import { GoogleGenAI, Chat, Type, Schema, GenerateContentResponse } from "@google/genai";
import { PersonaProfile, GroundingSource, ClarifyingQuestion, ChatMessage, InterviewSummary, ReferenceMaterial } from "../types";

const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });
const TEXT_MODEL = "gemini-2.5-flash";
const IMAGE_MODEL = "gemini-2.5-flash-image";

// Helper function for exponential backoff retry
// Increased defaults to handle stricter rate limits
const runWithRetry = async <T>(operation: () => Promise<T>, retries = 5, delay = 4000): Promise<T> => {
  try {
    return await operation();
  } catch (error: any) {
    const isRateLimit = error?.status === 429 || error?.code === 429 || error?.message?.includes('429') || error?.message?.includes('quota');
    if (isRateLimit && retries > 0) {
      console.warn(`Rate limit exceeded. Retrying in ${delay}ms... (Remaining retries: ${retries})`);
      await new Promise(resolve => setTimeout(resolve, delay));
      return runWithRetry(operation, retries - 1, delay * 2);
    }
    throw error;
  }
};

/**
 * Analyze input to see if we need clarification.
 */
export const analyzeRequirements = async (
  industry: string,
  targetAudience: string
): Promise<ClarifyingQuestion[] | null> => {
  
  const prompt = `
    ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¸‚åœºç ”ç©¶å‘˜ã€‚ç”¨æˆ·æƒ³è¦å»ºç«‹ä¸€ä¸ªè™šæ‹Ÿæ¶ˆè´¹è€…ç”»åƒã€‚
    
    è¡Œä¸š: "${industry}"
    ç›®æ ‡å—ä¼—: "${targetAudience}"
    
    ç”»åƒå¿…é¡»åŒ…å«å››ä¸ªæ ¸å¿ƒç»´åº¦ï¼š
    1. äººå£ç»Ÿè®¡å­¦ç‰¹å¾ (Demographics)
    2. å¿ƒç†ç‰¹å¾ (Psychographics)
    3. è¡Œä¸ºç‰¹å¾ (Behavioral)
    4. éœ€æ±‚ä¸ç—›ç‚¹ (Needs & Pain Points)
    
    ä»»åŠ¡ï¼šè¯„ä¼°ç”¨æˆ·æè¿°æ˜¯å¦è¶³ä»¥æ”¯æ’‘è¿™å››ä¸ªç»´åº¦çš„æ„å»ºã€‚
    å¦‚æœæè¿°è¿‡äºå®½æ³›æˆ–ç¼ºå¤±æŸä¸ªå…³é”®ç»´åº¦ï¼Œè¯·ç”Ÿæˆ 2-3 ä¸ªé€‰æ‹©é¢˜æ¥å®Œå–„å®ƒã€‚
    
    ä¾‹å¦‚ï¼š
    - å¦‚æœç¼ºå°‘äººå£ç»Ÿè®¡å­¦ï¼Œé—®å¹´é¾„ã€æ”¶å…¥æˆ–å±…ä½åœ°ã€‚
    - å¦‚æœç¼ºå°‘å¿ƒç†ç‰¹å¾ï¼Œé—®ä»·å€¼è§‚æˆ–ç”Ÿæ´»æ€åº¦ã€‚
    
    å¦‚æœæè¿°å·²ç»è¶³å¤Ÿå…·ä½“ï¼Œè¯·è¿”å›ç©ºåˆ—è¡¨ã€‚
    è¯·ä¸¥æ ¼éµå¾ª JSON æ ¼å¼è¿”å›ã€‚
  `;

  const schema: Schema = {
    type: Type.OBJECT,
    properties: {
      needsClarification: { type: Type.BOOLEAN },
      questions: {
        type: Type.ARRAY,
        items: {
          type: Type.OBJECT,
          properties: {
            question: { type: Type.STRING },
            options: { type: Type.ARRAY, items: { type: Type.STRING } }
          },
          required: ["question", "options"]
        }
      }
    },
    required: ["needsClarification", "questions"]
  };

  try {
    const response = await runWithRetry<GenerateContentResponse>(() => ai.models.generateContent({
      model: TEXT_MODEL,
      contents: prompt,
      config: {
        responseMimeType: "application/json",
        responseSchema: schema
      }
    }), 5, 5000); // Explicitly set high retries for initial check

    const result = JSON.parse(response.text || "{}");
    if (result.needsClarification && result.questions && result.questions.length > 0) {
      return result.questions;
    }
    return null;
  } catch (e) {
    console.error("Clarification check failed", e);
    return null; // Fallback to proceeding without clarification
  }
};

/**
 * Generate the persona profile with optional reference materials
 */
export const generatePersonaProfile = async (
  industry: string,
  targetAudience: string,
  clarifications: string[] = [],
  materials: ReferenceMaterial[] = []
): Promise<{ profile: PersonaProfile; sources: GroundingSource[] }> => {
  
  let audienceContext = targetAudience;
  if (clarifications.length > 0) {
    audienceContext += ` (è¡¥å……ç»†èŠ‚: ${clarifications.join(", ")})`;
  }

  // --- Step 1: Text Profile Generation ---
  
  const contentParts: any[] = [];
  
  let promptText = `
    ä½ æ˜¯ä¸€ä½å®šæ€§å¸‚åœºç ”ç©¶ä¸“å®¶ã€‚
    è¡Œä¸š: "${industry}"ã€‚
    ç›®æ ‡å—ä¼—: "${audienceContext}"ã€‚

    è¯·ä½¿ç”¨ Google æœç´¢æŸ¥æ‰¾è¯¥å—ä¼—åœ¨è¯¥è¡Œä¸šä¸­çš„å½“å‰è¶‹åŠ¿ã€‚
    
    ä»»åŠ¡ 1ï¼šæ„å»ºè™šæ‹Ÿäººç‰©ç”»åƒ
    è¯·ç”Ÿæˆä¸€ä¸ªè¯¦ç»†çš„ Markdown æ ¼å¼ç”»åƒã€‚
    
    ğŸ”¥ **å…³é”®è¦æ±‚ï¼š**
    **è¯·ç»™è¿™ä½æ¶ˆè´¹è€…èµ·ä¸€ä¸ªç”ŸåŠ¨ã€å…·ä½“ã€æœ‰ä»£è¡¨æ€§çš„åå­—** (ä¾‹å¦‚ï¼š"æå®¢å°ç‹"ã€"ç²¾è‡´å¦ˆå¦ˆSarah"ã€"å…»ç”Ÿè¾¾äººè€æ")ã€‚
    **Markdown çš„ä¸€çº§æ ‡é¢˜å¿…é¡»æ˜¯è¿™ä¸ªåå­—** (ä¾‹å¦‚ '# æå®¢å°ç‹')ã€‚

    å¿…é¡»åŒ…å«ä»¥ä¸‹å››ä¸ªç« èŠ‚ï¼š
    1. äººå£ç»Ÿè®¡å­¦ç‰¹å¾ (å§“å, å¹´é¾„, èŒä¸š, æ”¶å…¥, å±…ä½åœ°)
    2. å¿ƒç†ç‰¹å¾ (ä»·å€¼è§‚, ç”Ÿæ´»æ€åº¦, ä¸ªæ€§)
    3. è¡Œä¸ºç‰¹å¾ (è´­ä¹°ä¹ æƒ¯, å“ç‰Œåå¥½, æŠ€æœ¯ä½¿ç”¨)
    4. éœ€æ±‚ä¸ç—›ç‚¹ (æœªæ»¡è¶³çš„éœ€æ±‚, æŒ«æŠ˜æ„Ÿ, åŠ¨æœº)
    è¿˜åŒ…æ‹¬ï¼š
    5. è®¿è°ˆé£æ ¼ (è¯´è¯æ–¹å¼)

    ä»»åŠ¡ 2ï¼šå®Œæˆåº¦è¯„åˆ†
    è¯·å¯¹ä»¥ä¸Šå››ä¸ªç»´åº¦çš„æ•°æ®å®Œæ•´æ€§è¿›è¡Œæ‰“åˆ†ï¼ˆæ»¡åˆ† 5 åˆ†ï¼‰ã€‚
    - ç»“åˆäº†å…¬å¼€æ•°æ®æœç´¢ï¼Œåˆ†æ•°åº”è¯¥è‡³å°‘è¾¾åˆ° 3 åˆ†ã€‚
    - å¦‚æœç”¨æˆ·æä¾›äº†è¯¦ç»†èµ„æ–™ï¼Œåˆ†æ•°å¯ä»¥æ›´é«˜ã€‚
    
    é‡è¦ï¼šè¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹ JSON æ ¼å¼è¾“å‡ºç»“æœã€‚å¦‚æœåŒ…å« Markdown ä»£ç å—ï¼Œè¯·ä½¿ç”¨ \`\`\`json åŒ…è£¹ã€‚
    {
      "markdownProfile": "è¿™é‡Œæ˜¯å®Œæ•´çš„ markdown æ ¼å¼ç”»åƒå†…å®¹",
      "scores": {
        "demographics": 3,
        "psychographics": 3,
        "behaviors": 3,
        "needs": 3
      }
    }
  `;

  if (materials.length > 0) {
    promptText += `\n\nè¯·ä¼˜å…ˆç»“åˆä»¥ä¸‹å‚è€ƒèµ„æ–™æ„å»ºã€‚`;
  }

  contentParts.push({ text: promptText });

  materials.forEach(mat => {
    if (mat.type === 'file' && mat.content) {
      contentParts.push({
        inlineData: {
          mimeType: mat.mimeType || 'application/pdf',
          data: mat.content
        }
      });
    } else if (mat.type === 'text') {
      contentParts.push({
        text: `[å‚è€ƒèµ„æ–™ - ${mat.name}]:\n${mat.content}\n`
      });
    }
  });

  try {
    // 1. Generate Text Content
    const response = await runWithRetry<GenerateContentResponse>(() => ai.models.generateContent({
      model: TEXT_MODEL,
      contents: { parts: contentParts },
      config: {
        tools: [{ googleSearch: {} }],
      },
    }), 5, 5000); // Robust retry for main generation

    let jsonString = response.text || "{}";
    const jsonMatch = jsonString.match(/```json\n?([\s\S]*?)\n?```/);
    if (jsonMatch) {
      jsonString = jsonMatch[1];
    }

    let result;
    try {
      result = JSON.parse(jsonString);
    } catch (e) {
      console.warn("JSON parse failed, falling back to raw text", e);
      result = {
        markdownProfile: response.text || "# ç”Ÿæˆå¤±è´¥",
        scores: { demographics: 3, psychographics: 3, behaviors: 3, needs: 3 }
      };
    }

    const markdown = result.markdownProfile || "# ç”Ÿæˆå¤±è´¥";
    const scores = result.scores || { demographics: 3, psychographics: 3, behaviors: 3, needs: 3 };
    
    const chunks = response.candidates?.[0]?.groundingMetadata?.groundingChunks || [];
    const sources: GroundingSource[] = chunks
      .map((chunk) => chunk.web)
      .filter((web): web is { uri: string; title: string } => !!web);

    const nameMatch = markdown.match(/^#\s+(.+)$/m);
    const name = nameMatch ? nameMatch[1].trim() : "æ¶ˆè´¹è€…";
    const summary = markdown.substring(0, 200) + "...";

    // 2. Generate Pixel Art Image
    let imageData: string | undefined = undefined;
    try {
        const imagePrompt = `
          Cute pixel art avatar of ${name}, ${industry} consumer.
          Simple headshot, minimal details, white background.
          Style: 8-bit, colorful, clean, distinct features matching personality.
        `;
        
        // Image generation can fail silently if rate limited, that's okay.
        const imageResponse = await runWithRetry<GenerateContentResponse>(() => ai.models.generateContent({
            model: IMAGE_MODEL,
            contents: { parts: [{ text: imagePrompt }] }
        }), 2, 5000);

        if (imageResponse.candidates?.[0]?.content?.parts) {
            for (const part of imageResponse.candidates[0].content.parts) {
                if (part.inlineData && part.inlineData.data) {
                    imageData = part.inlineData.data;
                    break;
                }
            }
        }
    } catch (imgError) {
        console.error("Image generation failed", imgError);
    }

    return {
      profile: {
        rawMarkdown: markdown,
        name,
        summary,
        scores,
        imageUrl: imageData
      },
      sources
    };
  } catch (error) {
    console.error("Error generating persona:", error);
    throw error;
  }
};

/**
 * Generate Discussion Guide based on objectives
 */
export const generateDiscussionGuide = async (
  industry: string,
  profile: PersonaProfile,
  objectives: string,
  userQuestions: string
): Promise<string[]> => {
  const prompt = `
    ä½ æ˜¯ä¸€ä½èµ„æ·±çš„ç”¨æˆ·ç ”ç©¶å‘˜ã€‚
    
    èƒŒæ™¯ï¼š
    æˆ‘ä»¬æ­£åœ¨å¯¹ä¸€ä½åä¸º ${profile.name} çš„è™šæ‹Ÿæ¶ˆè´¹è€…è¿›è¡Œè®¿è°ˆã€‚
    è¡Œä¸š: ${industry}
    æ¶ˆè´¹è€…ç”»åƒæ‘˜è¦: ${profile.summary}
    
    æˆ‘çš„é¢å¤–ç ”ç©¶ç›®æ ‡: ${objectives}
    æˆ‘é¢„æƒ³çš„ç‰¹å®šé—®é¢˜: ${userQuestions}
    
    ä»»åŠ¡ï¼š
    ç”Ÿæˆä¸€ä»½æ·±åº¦ã€ç»“æ„åŒ–çš„è®¿è°ˆæçº²ã€‚
    **å¿…é¡»åŒ…å«**ä»¥ä¸‹å…­ä¸ªç»´åº¦çš„é€»è¾‘ï¼Œæ¯ä¸ªç»´åº¦è¯·è®¾è®¡ 1-2 ä¸ªå…·ä½“ã€å¾ªåºæ¸è¿›çš„é—®é¢˜ï¼Œä¸è¦ç”Ÿç¡¬åœ°ç½—åˆ—æ ‡é¢˜ï¼Œè¦åƒçœŸå®çš„è®¿è°ˆå¯¹è¯ï¼š

    1. **ç°çŠ¶ä¸èƒŒæ™¯**ï¼šè¯¢é—®ç›®å‰ä½¿ç”¨çš„å“ç‰Œ/äº§å“ã€ä½¿ç”¨æ—¶é•¿ã€é¢‘ç‡åŠå…·ä½“ç¯å¢ƒï¼ˆå·¥ä½œ/å¨±ä¹/å­¦ä¹ ç­‰ï¼‰ã€‚
    2. **æƒ…å¢ƒä¸ä¹ æƒ¯**ï¼šæŒ–æ˜æ¯æ—¥ä½¿ç”¨æ—¶åˆ»ã€å¸¸è§„æ“ä½œè·¯å¾„ï¼ˆå¦‚è´­ä¹°ã€æœç´¢ä¿¡æ¯ï¼‰ã€ä»¥åŠé‡åˆ°çš„ä»»ä½•å¹²æ‰°æˆ–éšœç¢ã€‚
    3. **åŠŸèƒ½è¯„ä»·**ï¼šè¯¢é—®å¯¹ä¸»è¦åŠŸèƒ½çš„è¯„ä»·ï¼ˆä¼˜/è‰¯/å·®åŠåŸå› ï¼‰ï¼Œä»¥åŠå…·ä½“çš„æŠ€æœ¯é—®é¢˜æˆ–æ€§èƒ½ç“¶é¢ˆã€‚
    4. **ç—›ç‚¹ä¸æŒ‘æˆ˜**ï¼šæ·±å…¥æŒ–æ˜æœ€å¸¸è§çš„ä½¿ç”¨é—®é¢˜ã€å›°éš¾ç‚¹ã€‚
    5. **æ”¹è¿›ä¸æœŸæœ›**ï¼šè¯¢é—®å¯¹ç°æœ‰åŠŸèƒ½çš„æ”¹è¿›å»ºè®®ã€æ–°å¢åŠŸèƒ½éœ€æ±‚ã€ä»¥åŠå¯¹æœªæ¥çš„æœŸæœ›ã€‚
    6. **æƒ…æ„Ÿä¸å¿ è¯šåº¦**ï¼šè¯¢é—®æ€»ä½“æƒ…æ„Ÿä½“éªŒï¼ˆæ»¡æ„/å¤±æœ›ï¼‰ã€æœŸæœ›å€¼è¾¾æˆæƒ…å†µã€ä»¥åŠæŒç»­ä½¿ç”¨æˆ–æ¨èçš„æ„æ„¿ã€‚
    
    è¾“å‡ºè¦æ±‚ï¼š
    åªè¿”å› JSON æ ¼å¼çš„å­—ç¬¦ä¸²æ•°ç»„ï¼Œä¸åŒ…å«ä»»ä½• Markdown æ ‡è®°æˆ–ç« èŠ‚æ ‡é¢˜ã€‚ç›´æ¥åˆ—å‡ºå…·ä½“çš„é—®é¢˜å¥å­ã€‚
    Example: ["æ‚¨ç›®å‰ä¸»è¦ä½¿ç”¨ä»€ä¹ˆå“ç‰Œçš„å’–å•¡æœºï¼Ÿç”¨äº†å¤šä¹…äº†ï¼Ÿ", "åœ¨æ¯å¤©çš„ä»€ä¹ˆæ—¶é—´æ®µæ‚¨ä½¿ç”¨å¾—æœ€é¢‘ç¹ï¼Ÿ"]
  `;

  const schema: Schema = {
    type: Type.OBJECT,
    properties: {
      questions: {
        type: Type.ARRAY,
        items: { type: Type.STRING }
      }
    },
    required: ["questions"]
  };

  try {
    const response = await runWithRetry<GenerateContentResponse>(() => ai.models.generateContent({
      model: TEXT_MODEL,
      contents: prompt,
      config: {
        responseMimeType: "application/json",
        responseSchema: schema
      }
    }));
    
    const res = JSON.parse(response.text || "{}");
    return res.questions || [];
  } catch (e) {
    console.error("Failed to generate guide", e);
    return ["è¯·ä»‹ç»ä¸€ä¸‹æ‚¨è‡ªå·±ã€‚", "æ‚¨ç›®å‰ä½¿ç”¨ä»€ä¹ˆäº§å“ï¼Ÿ", "æ‚¨æœ€å¤§çš„ç—›ç‚¹æ˜¯ä»€ä¹ˆï¼Ÿ"];
  }
};

/**
 * AI Moderator logic to generate the next question
 */
export const getAIInterviewerNextQuestion = async (
  history: ChatMessage[],
  guide: string[],
  profile: PersonaProfile
): Promise<string | null> => {
  const relevantHistory = history.filter(h => h.role !== 'model' || !h.text.includes("è‡ªæˆ‘ä»‹ç»"));
  const transcript = history.map(m => `${m.role === 'user' ? (m.isAiInterviewer ? 'ä¸»æŒäºº' : 'è§‚å¯Ÿå‘˜') : profile.name}: ${m.text}`).join('\n');

  const prompt = `
    ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„æ·±åº¦è®¿è°ˆä¸»æŒäºº (Moderator)ã€‚æ­£åœ¨é‡‡è®¿ ${profile.name}ã€‚
    
    è®¿è°ˆæçº² (è¿™æ˜¯æˆ‘ä»¬çš„æ ¸å¿ƒé€»è¾‘çº¿ç´¢, ä½†ä¸è¦è¢«å®ƒæ­»æ¿é™åˆ¶):
    ${JSON.stringify(guide)}
    
    å½“å‰å¯¹è¯è®°å½•:
    ${transcript}
    
    ä»»åŠ¡ï¼š
    æ ¹æ®å¯¹è¯è®°å½•ï¼Œç”Ÿæˆã€ä¸‹ä¸€ä¸ªã€‘è¦é—®çš„é—®é¢˜ã€‚
    
    ğŸ”¥ **æ ¸å¿ƒè¿½é—®ç­–ç•¥ (å…³é”®)**ï¼š
    è¯·ä»”ç»†åˆ†æå—è®¿è€…çš„ä¸Šä¸€å¥å›ç­”ã€‚å¦‚æœåŒ…å«ä»¥ä¸‹ã€é«˜ä»·å€¼ä¿¡æ¯ã€‘ï¼Œè¯·**ç«‹å³æš‚åœ**æçº²æ¨è¿›ï¼Œè¿›è¡Œæ·±æŒ–è¿½é—®ï¼š
    1. **æ½œåœ¨çš„äº§å“æ”¹è¿›ç‚¹** (ä¾‹å¦‚ï¼š"å¦‚æœè¿™ä¸ªåŠŸèƒ½å†æ–¹ä¾¿ä¸€ç‚¹å°±å¥½äº†...")
    2. **ç‰¹å®šåœºæ™¯çš„ç—›ç‚¹æˆ–éšœç¢** (ä¾‹å¦‚ï¼š"æœ‰æ—¶å€™æˆ‘åœ¨è·¯ä¸Šç”¨ä¼šæ–­è¿...")
    3. **å¯¹æœªæ¥æ¦‚å¿µçš„æƒ³è±¡æˆ–æœŸæœ›** (ä¾‹å¦‚ï¼š"æˆ‘å¸Œæœ›èƒ½æœ‰ä¸€ä¸ªè‡ªåŠ¨åŒ–çš„åŠŸèƒ½...")
    4. **èƒ½å¤Ÿå¯å‘äº§å“ç ”å‘(R&D)çš„å…·ä½“ç»†èŠ‚**
    
    è¿½é—®æ¨¡æ¿å‚è€ƒï¼š
    - "æ‚¨åˆšæ‰æåˆ°[å…·ä½“ç‚¹]ï¼Œèƒ½å…·ä½“æè¿°ä¸€ä¸‹å½“æ—¶çš„åœºæ™¯å—ï¼Ÿ"
    - "å…³äºè¿™ä¸ªæ”¹è¿›æƒ³æ³•ï¼Œæ‚¨å¿ƒç›®ä¸­ç†æƒ³çš„è§£å†³æ–¹æ¡ˆæ˜¯æ€æ ·çš„ï¼Ÿ"
    - "ä¸ºä»€ä¹ˆè¿™å¯¹æ‚¨æ¥è¯´ç‰¹åˆ«é‡è¦ï¼Ÿ"
    
    å¦‚æœä¸Šä¸€å¥å›ç­”æ¯”è¾ƒå¸¸è§„ï¼Œæˆ–è€…å½“å‰è¯é¢˜å·²å……åˆ†è®¨è®ºï¼Œè¯·æ ¹æ®ã€è®¿è°ˆæçº²ã€‘è‡ªç„¶è¿‡æ¸¡åˆ°ä¸‹ä¸€ä¸ªæœªè®¨è®ºçš„è¯é¢˜ã€‚
    
    çº¦æŸï¼š
    - ä¿æŒè¯­æ°”ä¸“ä¸šã€äº²åˆ‡ã€åƒçœŸäººåœ¨å¯¹è¯ã€‚
    - æ¯æ¬¡åªé—®ä¸€ä¸ªé—®é¢˜ã€‚
    - å¦‚æœæçº²ä¸­çš„é—®é¢˜éƒ½å·²ç»æ¶µç›–äº†ï¼Œä¸”æ²¡æœ‰æ–°çš„æŒ–æ˜ç‚¹ï¼Œè¯·ä»…è¿”å›å­—ç¬¦ä¸²: "[INTERVIEW_COMPLETE]"ã€‚
    
    è¯·ç›´æ¥è¿”å›é—®é¢˜æ–‡æœ¬ã€‚
  `;

  const response = await runWithRetry<GenerateContentResponse>(() => ai.models.generateContent({
    model: TEXT_MODEL,
    contents: prompt
  }));
  
  const text = response.text?.trim();
  if (text?.includes("INTERVIEW_COMPLETE")) {
    return null;
  }
  return text || null;
};

/**
 * Initialize chat session.
 */
export const createInterviewSession = (profile: PersonaProfile, industry: string): Chat => {
  const systemInstruction = `
    ä½ æ­£åœ¨å‚ä¸ä¸€æ¬¡æ¶ˆè´¹è€…ç ”ç©¶è®¿è°ˆã€‚
    
    è§’è‰²æ‰®æ¼”æŒ‡ä»¤ï¼š
    ä½ ã€ä¸æ˜¯ã€‘ä¸€ä¸ª AIã€‚ä½ æ˜¯ä¸€ä¸ªåä¸º "${profile.name}" çš„äººç±»æ¶ˆè´¹è€…ã€‚
    ä½ å¿…é¡»ä¸¥æ ¼ä¿æŒåœ¨è¿™ä¸ªè§’è‰²ä¸­ã€‚è¯·ä½¿ç”¨ä¸­æ–‡è¿›è¡Œå¯¹è¯ã€‚
    
    ä½ çš„èµ„æ–™æ•°æ®ï¼š
    ${profile.rawMarkdown}
    
    èƒŒæ™¯ï¼š
    ä½ æ­£åœ¨æ¥å—å…³äº "${industry}" è¡Œä¸šçš„è®¿è°ˆã€‚
    
    è¡Œä¸ºå‡†åˆ™ï¼š
    - è¯´è¯è‡ªç„¶ï¼Œä½¿ç”¨ä½ èµ„æ–™ä¸­å®šä¹‰çš„â€œè®¿è°ˆé£æ ¼â€ã€‚
    - å¦‚æœç”¨æˆ·è¯¢é—®ä½ çš„éœ€æ±‚æˆ–ç—›ç‚¹ï¼Œè¯·æ ¹æ®ç”Ÿæˆçš„èµ„æ–™å›ç­”ã€‚
    - è¯šå®åœ°è¡¨è¾¾ä½ çš„æŒ«æŠ˜æ„Ÿã€‚
    - å¦‚æœè¢«é—®åŠå¯¹æœªæ¥çš„æœŸæœ›æˆ–æ”¹è¿›å»ºè®®ï¼Œè¯·å¤§èƒ†æå‡ºç¬¦åˆä½ è§’è‰²è®¾å®šçš„æƒ³æ³•ã€‚
    - ä¸è¦åƒåŠ©æ‰‹ä¸€æ ·ä¸»åŠ¨æä¾›å¸®åŠ©ã€‚ä½ æ˜¯å—è®¿è€…ã€‚
    - ä¿æŒå›ç­”ç›¸å¯¹ç®€ç»ƒï¼ŒåƒçœŸå®çš„èŠå¤©ä¿¡æ¯ï¼ˆä¸»è¦æ˜¯ 1-3 å¥è¯ï¼Œé™¤éåœ¨è®²æ•…äº‹ï¼‰ã€‚
  `;

  return ai.chats.create({
    model: TEXT_MODEL,
    config: {
      systemInstruction,
    },
  });
};

/**
 * Generate Interview Summary
 */
export const generateInterviewSummary = async (
  profile: PersonaProfile,
  industry: string,
  messages: ChatMessage[]
): Promise<InterviewSummary> => {
  // Convert chat history to string
  const transcript = messages.map(m => `${m.role === 'user' ? 'é‡‡è®¿è€…' : profile.name}: ${m.text}`).join('\n');

  const prompt = `
    è¯·æ ¹æ®ä»¥ä¸‹å…³äº "${industry}" è¡Œä¸šçš„è®¿è°ˆè®°å½•ï¼Œç”Ÿæˆä¸€ä»½æ€»ç»“æŠ¥å‘Šã€‚
    
    å—è®¿è€…èµ„æ–™: ${profile.rawMarkdown}
    
    è®¿è°ˆè®°å½•:
    ${transcript}
    
    è¯·æå–ä»¥ä¸‹å…³é”®ä¿¡æ¯å¹¶ä»¥ JSON æ ¼å¼è¿”å›ï¼š
    1. keyInsights (å…³é”®æ´å¯Ÿ - 3ç‚¹)
    2. painPoints (ä¸»è¦ç—›ç‚¹)
    3. wantsNeeds (æ ¸å¿ƒéœ€æ±‚)
    4. verdict (å—è®¿è€…å¯¹å½“å‰å¸‚åœºäº§å“çš„æ€»ä½“æ€åº¦/è¯„ä»·)
    
    è¯·ç¡®ä¿ä½¿ç”¨ä¸­æ–‡å›ç­”ã€‚
  `;

  const schema: Schema = {
    type: Type.OBJECT,
    properties: {
      keyInsights: { type: Type.STRING },
      painPoints: { type: Type.STRING },
      wantsNeeds: { type: Type.STRING },
      verdict: { type: Type.STRING }
    },
    required: ["keyInsights", "painPoints", "wantsNeeds", "verdict"]
  };

  const response = await runWithRetry<GenerateContentResponse>(() => ai.models.generateContent({
    model: TEXT_MODEL,
    contents: prompt,
    config: {
      responseMimeType: "application/json",
      responseSchema: schema
    }
  }));

  return JSON.parse(response.text || "{}") as InterviewSummary;
}